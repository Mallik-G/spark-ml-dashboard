{"paragraphs":[{"text":"%spark.pyspark\n\nfrom pyspark.sql import DataFrame\nfrom pyspark.ml import *    ","dateUpdated":"2017-01-10T05:31:57+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036425_693548635","id":"20161231-024148_1037434963","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2016-12-31T19:37:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:190","dateFinished":"2017-01-10T05:31:57+0000","dateStarted":"2017-01-10T05:31:57+0000","focus":true},{"text":"print(\"%html <h1>Load Training and Test Data as DataSets</h1>\")","dateUpdated":"2016-12-31T19:37:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036425_693548635","id":"20161231-185313_1975190697","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Load Training and Test Data as DataSets</h1>"},"dateCreated":"2016-12-31T19:37:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:191"},{"text":"import org.apache.spark.sql.types._\nimport org.apache.spark.sql.Row\nimport spark.implicits._\nimport org.apache.spark.sql.Dataset\n\ndef load(path: String): Dataset[Row] = {\n    var docs = sc.wholeTextFiles(path).cache()\n\n    // convert docs which is tuple2 RDD into Row RDD\n    var rowRDD = docs.map(x =>{\n        var t = x._1.split(\"/\")\n        var id = t(t.size-1)\n        var topic = t(t.size-2)\n        var label = if (topic.startsWith(\"sci\")) 1.0 else 0.0\n        Row(id, topic, label, x._2)\n        })\n    \n    // Schema generation\n    val schemaString = \"id:String topic:String label:Double text:String\"\n    val fields = schemaString.split(\" \").map(fieldName => {\n            var nameAndType = fieldName.split(\":\")\n            var fieldType = if (nameAndType(1).equals(\"Double\")) DoubleType else StringType\n            StructField(nameAndType(0), fieldType, nullable = true)\n        })\n    val schema = StructType(fields)\n    \n    // convert Row RDD into DataSet\n    return sqlContext.createDataFrame(rowRDD, schema).cache()\n}\n\nvar training = load(\"/tmp/20news-bydate/20news-bydate-train/*/\")\nvar test = load(\"/tmp/20news-bydate/20news-bydate-test/*/\")","dateUpdated":"2017-01-10T05:32:00+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036425_693548635","id":"20161231-170323_352688296","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.sql.types._\n\nimport org.apache.spark.sql.Row\n\nimport spark.implicits._\n\nimport org.apache.spark.sql.Dataset\n\nload: (path: String)org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\n\ntraining: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: string, topic: string ... 2 more fields]\n\ntest: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [id: string, topic: string ... 2 more fields]\n"},"dateCreated":"2016-12-31T19:37:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:192","dateFinished":"2017-01-10T05:32:03+0000","dateStarted":"2017-01-10T05:32:01+0000","focus":true},{"text":"print(\"%html <h1> Print some counts/stats for Training and Test Data</h1>\")","dateUpdated":"2016-12-31T19:37:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036425_693548635","id":"20161231-185557_1849176262","result":{"code":"SUCCESS","type":"HTML","msg":"<h1> Print some counts/stats for Training and Test Data</h1>"},"dateCreated":"2016-12-31T19:37:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:193"},{"text":"println(\"Total Training Docs: \" + training.count())\nprintln(\"Total Test Docs: \" + test.count())\ntraining.groupBy(\"topic\").count().show()\ntraining.groupBy(\"label\").count().show()\ntraining.groupBy(\"topic\").count().show()\ntest.groupBy(\"label\").count().show()","dateUpdated":"2017-01-10T05:32:11+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036425_693548635","id":"20161231-170546_477317730","result":{"code":"SUCCESS","type":"TEXT","msg":"Total Training Docs: 11314\nTotal Test Docs: 7532\n+--------------------+-----+\n|               topic|count|\n+--------------------+-----+\n|      comp.windows.x|  593|\n|        misc.forsale|  585|\n|    rec.sport.hockey|  600|\n|  rec.sport.baseball|  597|\n|  talk.politics.guns|  546|\n|comp.os.ms-window...|  591|\n|  talk.politics.misc|  465|\n|comp.sys.ibm.pc.h...|  590|\n|       comp.graphics|  584|\n|soc.religion.chri...|  599|\n|comp.sys.mac.hard...|  578|\n|  talk.religion.misc|  377|\n|talk.politics.mid...|  564|\n|     rec.motorcycles|  598|\n|           rec.autos|  594|\n|         alt.atheism|  480|\n|     sci.electronics|  591|\n|           sci.space|  593|\n|             sci.med|  594|\n|           sci.crypt|  595|\n+--------------------+-----+\n\n+-----+-----+\n|label|count|\n+-----+-----+\n|  0.0| 8941|\n|  1.0| 2373|\n+-----+-----+\n\n+--------------------+-----+\n|               topic|count|\n+--------------------+-----+\n|      comp.windows.x|  593|\n|        misc.forsale|  585|\n|    rec.sport.hockey|  600|\n|  rec.sport.baseball|  597|\n|  talk.politics.guns|  546|\n|comp.os.ms-window...|  591|\n|  talk.politics.misc|  465|\n|comp.sys.ibm.pc.h...|  590|\n|       comp.graphics|  584|\n|soc.religion.chri...|  599|\n|comp.sys.mac.hard...|  578|\n|  talk.religion.misc|  377|\n|talk.politics.mid...|  564|\n|     rec.motorcycles|  598|\n|           rec.autos|  594|\n|         alt.atheism|  480|\n|     sci.electronics|  591|\n|           sci.space|  593|\n|             sci.med|  594|\n|           sci.crypt|  595|\n+--------------------+-----+\n\n+-----+-----+\n|label|count|\n+-----+-----+\n|  0.0| 5953|\n|  1.0| 1579|\n+-----+-----+\n\n"},"dateCreated":"2016-12-31T19:37:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:194","dateFinished":"2017-01-10T05:35:43+0000","dateStarted":"2017-01-10T05:32:11+0000","focus":true},{"text":"print(\"%html <h1>Create Pipeline with a Tokenizer, HashingTF and LogisticRegression </h1>\")","dateUpdated":"2016-12-31T19:37:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036425_693548635","id":"20161231-185700_1988673502","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Create Pipeline with a Tokenizer, HashingTF and LogisticRegression </h1>"},"dateCreated":"2016-12-31T19:37:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:195"},{"text":"import org.apache.spark.ml.feature.RegexTokenizer\nval tokenizer = new RegexTokenizer()\n  .setInputCol(\"text\")\n  .setOutputCol(\"words\")\n  .setPattern(\"\\\\s+\")\n\nimport org.apache.spark.ml.feature.HashingTF\nval hashingTF = new HashingTF()\n  .setInputCol(tokenizer.getOutputCol)  // it does not wire transformers -- it's just a column name\n  .setOutputCol(\"features\")\n  .setNumFeatures(5000)\n \nimport org.apache.spark.ml.classification.LogisticRegression\nval lr = new LogisticRegression().setMaxIter(20).setRegParam(0.01)\n\nimport org.apache.spark.ml.Pipeline\nval pipeline = new Pipeline().setStages(Array(tokenizer, hashingTF, lr))\n\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\nval evaluator = new BinaryClassificationEvaluator().setMetricName(\"areaUnderROC\")\n\nimport org.apache.spark.ml.param.ParamMap\nval evaluatorParams = ParamMap(evaluator.metricName -> \"areaUnderROC\")\n","dateUpdated":"2017-01-10T05:37:27+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036425_693548635","id":"20161231-170010_1750591172","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.ml.feature.RegexTokenizer\n\ntokenizer: org.apache.spark.ml.feature.RegexTokenizer = regexTok_74aa95733a0d\n\nimport org.apache.spark.ml.feature.HashingTF\n\nhashingTF: org.apache.spark.ml.feature.HashingTF = hashingTF_5e435011f5a5\n\nimport org.apache.spark.ml.classification.LogisticRegression\n\nlr: org.apache.spark.ml.classification.LogisticRegression = logreg_2be4a9a4df41\n\nimport org.apache.spark.ml.Pipeline\n\npipeline: org.apache.spark.ml.Pipeline = pipeline_41a6d72dad58\n\nimport org.apache.spark.ml.evaluation.BinaryClassificationEvaluator\n\nevaluator: org.apache.spark.ml.evaluation.BinaryClassificationEvaluator = binEval_ff6811831baf\n\nimport org.apache.spark.ml.param.ParamMap\n\n\n\n\nevaluatorParams: org.apache.spark.ml.param.ParamMap =\n{\n\tbinEval_ff6811831baf-metricName: areaUnderROC\n}\n"},"dateCreated":"2016-12-31T19:37:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:196","dateFinished":"2017-01-10T05:37:29+0000","dateStarted":"2017-01-10T05:37:27+0000","focus":true},{"text":"print(\"%html <h1>Fit Model and check AreaUnderROC</h1>\")","dateUpdated":"2016-12-31T19:37:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036426_694702881","id":"20161231-185807_1850117452","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Fit Model and check AreaUnderROC</h1>"},"dateCreated":"2016-12-31T19:37:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:197"},{"text":"val model = pipeline.fit(training)\nval trainPredictions = model.transform(training)\nval testPredictions = model.transform(test)\nval areaTrain = evaluator.evaluate(trainPredictions, evaluatorParams)\nval areaTest = evaluator.evaluate(testPredictions, evaluatorParams)\n","dateUpdated":"2017-01-10T05:37:34+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036426_694702881","id":"20161231-173942_114320073","result":{"code":"SUCCESS","type":"TEXT","msg":"\nmodel: org.apache.spark.ml.PipelineModel = pipeline_41a6d72dad58\n\ntrainPredictions: org.apache.spark.sql.DataFrame = [id: string, topic: string ... 7 more fields]\n\ntestPredictions: org.apache.spark.sql.DataFrame = [id: string, topic: string ... 7 more fields]\n\nareaTrain: Double = 0.9998885798755743\n\nareaTest: Double = 0.9048976322548563\n"},"dateCreated":"2016-12-31T19:37:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:198","dateFinished":"2017-01-10T05:37:46+0000","dateStarted":"2017-01-10T05:37:34+0000","focus":true},{"text":"print(\"%html <h1>Now, let's try k-fold</h1>\")","dateUpdated":"2016-12-31T19:37:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036426_694702881","id":"20161231-185843_1070912397","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Now, let's try k-fold</h1>"},"dateCreated":"2016-12-31T19:37:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:199"},{"text":"import org.apache.spark.ml.tuning.ParamGridBuilder\nval paramGrid = new ParamGridBuilder()\n  .addGrid(hashingTF.numFeatures, Array(1000, 10000))\n  .addGrid(lr.regParam, Array(0.05, 0.2))\n  .addGrid(lr.maxIter, Array(5, 10, 15))\n  .build\n  \nimport org.apache.spark.ml.tuning.CrossValidator\nimport org.apache.spark.ml.param._\nval cv = new CrossValidator()\n  .setEstimator(pipeline)\n  .setEstimatorParamMaps(paramGrid)\n  .setEvaluator(evaluator)\n  .setNumFolds(2)\n\nval cvModel = cv.fit(training)","dateUpdated":"2017-01-10T05:37:51+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036426_694702881","id":"20161231-175123_1254250725","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.ml.tuning.ParamGridBuilder\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nparamGrid: Array[org.apache.spark.ml.param.ParamMap] =\nArray({\n\tlogreg_2be4a9a4df41-maxIter: 5,\n\thashingTF_5e435011f5a5-numFeatures: 1000,\n\tlogreg_2be4a9a4df41-regParam: 0.05\n}, {\n\tlogreg_2be4a9a4df41-maxIter: 10,\n\thashingTF_5e435011f5a5-numFeatures: 1000,\n\tlogreg_2be4a9a4df41-regParam: 0.05\n}, {\n\tlogreg_2be4a9a4df41-maxIter: 15,\n\thashingTF_5e435011f5a5-numFeatures: 1000,\n\tlogreg_2be4a9a4df41-regParam: 0.05\n}, {\n\tlogreg_2be4a9a4df41-maxIter: 5,\n\thashingTF_5e435011f5a5-numFeatures: 10000,\n\tlogreg_2be4a9a4df41-regParam: 0.05\n}, {\n\tlogreg_2be4a9a4df41-maxIter: 10,\n\thashingTF_5e435011f5a5-numFeatures: 10000,\n\tlogreg_2be4a9a4df41-regParam: 0.05\n}, {\n\tlogreg_2be4a9a4df41-maxIter: 15,\n\thashingTF_5e435011f5a5-numFeatures: 10000,\n\tlogreg_2be4a9a4df41-regParam: 0.05\n}, {\n\tlogreg_2be4a9a4df41-maxI...\nimport org.apache.spark.ml.tuning.CrossValidator\n\nimport org.apache.spark.ml.param._\n\ncv: org.apache.spark.ml.tuning.CrossValidator = cv_b382bcbf4ac6\n\ncvModel: org.apache.spark.ml.tuning.CrossValidatorModel = cv_b382bcbf4ac6\n"},"dateCreated":"2016-12-31T19:37:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:200","dateFinished":"2017-01-10T05:39:18+0000","dateStarted":"2017-01-10T05:37:51+0000","focus":true},{"text":"print(\"%html <h1>Calculate AreaUnderROC for test data with K-Fold</h1>\")","dateUpdated":"2016-12-31T19:37:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036426_694702881","id":"20161231-185929_159153150","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Calculate AreaUnderROC for test data with K-Fold</h1>"},"dateCreated":"2016-12-31T19:37:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:201"},{"text":"evaluator.evaluate(cvModel.transform(test))","dateUpdated":"2017-01-10T06:15:27+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"tableHide":false},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036426_694702881","id":"20161231-175912_279234146","result":{"code":"SUCCESS","type":"TEXT","msg":"\nres46: Double = 0.929696704829578\n"},"dateCreated":"2016-12-31T19:37:16+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:202","dateFinished":"2017-01-10T05:42:49+0000","dateStarted":"2017-01-10T05:42:47+0000","focus":true},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1484028931598_-1079261233","id":"20170110-061531_1596539710","dateCreated":"2017-01-10T06:15:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1854","text":"print(\"%html <h1>Get Best Params</h1>\")","dateUpdated":"2017-01-10T06:15:51+0000","dateFinished":"2017-01-10T06:15:52+0000","dateStarted":"2017-01-10T06:15:51+0000","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Get Best Params</h1>"}},{"config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1484026278658_236720393","id":"20170110-053118_407975192","dateCreated":"2017-01-10T05:31:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:1379","text":"println(cvModel.getEstimatorParamMaps.zip(cvModel.avgMetrics).maxBy(_._2)._1)","dateUpdated":"2017-01-10T06:16:15+0000","dateFinished":"2017-01-10T06:16:16+0000","dateStarted":"2017-01-10T06:16:15+0000","result":{"code":"SUCCESS","type":"TEXT","msg":"{\n\tlogreg_2be4a9a4df41-maxIter: 10,\n\thashingTF_5e435011f5a5-numFeatures: 10000,\n\tlogreg_2be4a9a4df41-regParam: 0.2\n}\n"}},{"text":"print(\"%html <h1>Save Predictions and Model</h1>\")","dateUpdated":"2016-12-31T19:37:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036426_694702881","id":"20161231-190018_1547659922","result":{"code":"SUCCESS","type":"HTML","msg":"<h1>Save Predictions and Model</h1>"},"dateCreated":"2016-12-31T19:37:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:203"},{"text":"cvModel.transform(test).select(\"id\", \"prediction\").write.json(\"s3://20news-bydate-predictions1.json\")","dateUpdated":"2016-12-31T19:37:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","tableHide":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036426_694702881","id":"20161231-180858_1703015781","result":{"code":"ERROR","type":"TEXT","msg":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\norg.apache.spark.sql.AnalysisException: path s3://20news-bydate-predictions1.json already exists.;\n  at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:88)\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:115)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:115)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:136)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:133)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:114)\n  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:86)\n  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:86)\n  at org.apache.spark.sql.execution.datasources.DataSource.write(DataSource.scala:525)\n  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:211)\n  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:194)\n  at org.apache.spark.sql.DataFrameWriter.json(DataFrameWriter.scala:467)\n  ... 96 elided\n"},"dateCreated":"2016-12-31T19:37:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:204"},{"text":"cvModel.write.overwrite.save(\"/tmp/model\")","dateUpdated":"2016-12-31T19:37:16+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036426_694702881","id":"20161231-181325_1223305741","result":{"code":"SUCCESS","type":"TEXT","msg":""},"dateCreated":"2016-12-31T19:37:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:205"},{"text":"","dateUpdated":"2016-12-31T19:37:16+0000","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1483213036427_694318132","id":"20161231-182749_1687965120","dateCreated":"2016-12-31T19:37:16+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:206"}],"name":"20news-bydate classification","id":"2C4JNN9PX","angularObjects":{"2BRWU4WXC:shared_process":[],"2AM1YV5CU:shared_process":[],"2AJXGMUUJ:shared_process":[],"2ANGGHHMQ:shared_process":[],"2AKK3QQXU:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}